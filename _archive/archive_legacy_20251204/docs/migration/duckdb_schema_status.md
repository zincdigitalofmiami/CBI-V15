# DuckDB Schema Status vs BigQuery

**Date:** December 3, 2024  
**Comparison:** External Drive DuckDB vs BigQuery Schema

---

## Summary

**BigQuery:** 7 datasets, 46 tables, 354 columns  
**DuckDB (Current):** 7 datasets, 6 tables loaded, ~3.7M rows

**Status:** ✅ Schemas created, ⚠️ Partial data migration (only tables with data were loaded)

---

## Current DuckDB State

### Loaded Tables (6 tables)

| Dataset | Table | Columns | Rows | Status |
|---------|-------|---------|------|--------|
| `raw` | `fred_economic` | 3 | 118,102 | ✅ Loaded |
| `raw` | `databento_futures_ohlcv_1d` | 8 | 180,186 | ✅ Loaded |
| `raw` | `databento_futures_ohlcv_1h` | 9 | 3,162,810 | ✅ Loaded |
| `staging` | `market_daily` | 8 | 137,153 | ✅ Loaded |
| `training` | `daily_ml_matrix` | 67 | 137,153 | ✅ Loaded |
| `ops` | `ingestion_completion` | 6 | 9 | ✅ Loaded |

**Total Rows Loaded:** 3,735,413

---

## Missing Tables (40 tables)

### Raw Dataset (8 missing)

- `scrapecreators_trump` (4 cols)
- `usda_reports` (5 cols)
- `cftc_cot` (6 cols)
- `scrapecreators_news_buckets` (15 cols)
- `weather_noaa` (5 cols)
- `databento_futures_statistics` (8 cols)
- `eia_biofuels` (3 cols)
- `test_table` (2 cols)

**Note:** These tables had 0 rows in BigQuery audit, so they weren't exported.

### Staging Dataset (8 missing)

- `news_bucketed` (11 cols)
- `eia_biofuels_clean` (3 cols)
- `cftc_positions` (4 cols)
- `sentiment_buckets` (8 cols)
- `fred_macro_clean` (4 cols)
- `weather_regions_aggregated` (4 cols)
- `usda_reports_clean` (5 cols)
- `trump_policy_intelligence` (3 cols)

**Note:** These tables had 0 rows in BigQuery audit.

### Features Dataset (12 missing - ALL)

- `neural_master_score` (2 cols)
- `fx_indicators_daily` (19 cols)
- `cross_asset_betas_daily` (6 cols)
- `regime_indicators_daily` (5 cols)
- `fundamental_spreads_daily` (6 cols)
- `pair_correlations_daily` (9 cols)
- `lagged_features_daily` (16 cols)
- `sentiment_features_daily` (9 cols)
- `trump_news_features_daily` (7 cols)
- `neural_signals_daily` (4 cols)
- `technical_indicators_us_oil_solutions` (21 cols)
- `daily_ml_matrix` (2 cols - placeholder view)

**Note:** All feature tables had 0 rows in BigQuery audit. Features are computed dynamically in `training.daily_ml_matrix`.

### Training Dataset (4 missing)

- `zl_training_1w` (4 cols)
- `zl_training_1m` (4 cols)
- `zl_training_3m` (4 cols)
- `zl_training_6m` (4 cols)

**Note:** These tables had 0 rows in BigQuery audit. Training sets are likely generated from `daily_ml_matrix`.

### Forecasts Dataset (4 missing - ALL)

- `zl_predictions_1w` (5 cols)
- `zl_predictions_1m` (5 cols)
- `zl_predictions_3m` (5 cols)
- `zl_predictions_6m` (5 cols)

**Note:** All forecast tables had 0 rows in BigQuery audit. Forecasts are generated by models.

### Reference Dataset (4 missing - ALL)

- `regime_calendar` (6 cols)
- `regime_weights` (7 cols)
- `train_val_test_splits` (3 cols)
- `neural_drivers` (5 cols)

**Note:** All reference tables had 0 rows in BigQuery audit. These are configuration/metadata tables.

---

## Schema Mismatches

### `ops.ingestion_completion`

**Type Mismatches:** 2 columns
- Check comparison file for details: `scripts/migration/schema_comparison.json`

---

## Row Count Comparison

All loaded tables show **more rows in DuckDB than BigQuery audit** because:
1. BigQuery audit queried tables that may have been empty at audit time
2. Data was loaded from Parquet exports which had actual data
3. DuckDB row counts are accurate: **3,735,413 total rows**

**Verified Integrity:** ✅ All loaded tables match Parquet export row counts

---

## Next Steps

### Immediate Actions

1. **Create Empty Tables** - Create schema for all 40 missing tables (even if empty):
   ```sql
   -- Example: Create empty table matching BigQuery schema
   CREATE TABLE raw.scrapecreators_trump (
       date DATE,
       post_id VARCHAR,
       content VARCHAR,
       policy_score DOUBLE
   );
   ```

2. **Load Reference Tables** - These are critical for regime classification:
   - `reference.regime_calendar`
   - `reference.regime_weights`
   - `reference.train_val_test_splits`
   - `reference.neural_drivers`

3. **Fix Type Mismatches** - Update `ops.ingestion_completion` column types

### Future Actions

4. **Backfill Empty Tables** - When data becomes available:
   - Raw data sources (USDA, EIA, CFTC, Weather, ScrapeCreators)
   - Staging cleaned tables
   - Feature tables (if pre-computed)
   - Forecast tables (when models run)

5. **Validate Feature Pipeline** - Ensure `training.daily_ml_matrix` can be rebuilt from loaded data

---

## Migration Script Status

- ✅ `rapid_bq_audit.py` - Completed (46 tables cataloged)
- ✅ `get_bq_schemas.py` - Completed (354 columns documented)
- ✅ `create_duckdb_schema.py` - Completed (7 schemas created)
- ✅ `export_bq_to_parquet.py` - Completed (6 tables with data exported)
- ✅ `load_parquet_to_duckdb.py` - Completed (6 tables loaded)
- ✅ `compare_duckdb_schema.py` - Completed (comparison generated)

**Next:** Create script to generate empty table schemas for all missing tables.

---

**Last Updated:** December 3, 2024

